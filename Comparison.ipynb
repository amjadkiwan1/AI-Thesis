{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity analysis complete. Results saved to Similarity_Analysis_few_shot_with_training.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "# Load the training data and generated questions data\n",
    "with open('formatted_train.jsonl', 'r') as f:\n",
    "    training_data = [json.loads(line) for line in f]\n",
    "\n",
    "with open('generated_test_results_few_shot.jsonl', 'r') as f:\n",
    "    generated_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Define a function to extract combined question and choices text for comparison\n",
    "def extract_combined_text(data_entry):\n",
    "    \"\"\"\n",
    "    Extract the combined question and choices text from the data entry for comparison, ignoring the answer.\n",
    "\n",
    "    Args:\n",
    "        data_entry (dict): A single data entry from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted combined text.\n",
    "    \"\"\"\n",
    "    if 'output' in data_entry:\n",
    "        output_text = data_entry['output']\n",
    "        question_start = output_text.find(\"Question:\") + len(\"Question:\")\n",
    "        choices_start = output_text.find(\"Choices:\")\n",
    "        question_text = output_text[question_start:choices_start].strip()\n",
    "        choices_text = output_text[choices_start:].strip()  # Include choices but ignore the answer\n",
    "        return f\"{question_text} {choices_text}\"\n",
    "    elif 'generated_response' in data_entry:\n",
    "        response_text = data_entry['generated_response']\n",
    "        question_start = response_text.find(\"Question:\") + len(\"Question:\")\n",
    "        choices_start = response_text.find(\"Choices:\")\n",
    "        question_text = response_text[question_start:choices_start].strip()\n",
    "        choices_text = response_text[choices_start:].strip()  # Include choices but ignore the answer\n",
    "        return f\"{question_text} {choices_text}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Define a function to calculate similarity\n",
    "def calculate_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two text inputs.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): First text input.\n",
    "        text2 (str): Second text input.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Compare generated questions with training data for similarity\n",
    "results = []\n",
    "total_similarity = 0\n",
    "num_comparisons = 0\n",
    "max_similarity_overall = 0.0\n",
    "\n",
    "for gen_entry in generated_data:\n",
    "    gen_input = gen_entry.get('input', '')\n",
    "    gen_combined = extract_combined_text(gen_entry)\n",
    "\n",
    "    max_similarity = 0.0\n",
    "    most_similar_training_question = \"\"\n",
    "\n",
    "    for train_entry in training_data:\n",
    "        train_input = train_entry.get('input', '')\n",
    "\n",
    "        if gen_input == train_input:  # Match based on the same input\n",
    "            train_combined = extract_combined_text(train_entry)\n",
    "\n",
    "            similarity = calculate_similarity(gen_combined, train_combined)\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_training_question = train_combined\n",
    "\n",
    "            total_similarity += similarity\n",
    "            num_comparisons += 1\n",
    "\n",
    "    # Update overall max similarity\n",
    "    if max_similarity > max_similarity_overall:\n",
    "        max_similarity_overall = max_similarity\n",
    "\n",
    "    # Store only the highest similarity\n",
    "    results.append({\n",
    "        \"Generated Question\": gen_combined,\n",
    "        \"Most Similar Training Question\": most_similar_training_question,\n",
    "        \"Highest Similarity Percentage\": round(max_similarity * 100, 2)\n",
    "    })\n",
    "\n",
    "# Calculate the overall average similarity\n",
    "average_similarity = (total_similarity / num_comparisons) * 100 if num_comparisons > 0 else 0\n",
    "\n",
    "# Save the results to a JSON file\n",
    "output = {\n",
    "    \"Results\": results,\n",
    "    \"Overall Average Similarity Percentage\": round(average_similarity, 2),\n",
    "    \"Highest Similarity Overall Percentage\": round(max_similarity_overall * 100, 2)\n",
    "}\n",
    "\n",
    "with open('Similarity_Analysis_few_shot_with_training.jsonl', 'w') as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(\"Similarity analysis complete. Results saved to Similarity_Analysis_few_shot_with_training.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Similarity analysis complete. Results saved to Generated_Questions_Similarity_Analysis_few_shot_LLaMA_with_generated_fULL_LLaMA.jsonl and summary to Generated_Questions_Similarity_Analysis_few_shot_LLaMA_with_generated_fULL_LLaMA_summary.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load JSONL files\n",
    "def load_jsonl(filename):\n",
    "    \"\"\"Load a JSONL file into a list of dictionaries.\"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line.strip()))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping malformed JSON line in {filename}\")\n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "training_data = load_jsonl('generated_test_results_FULL_LLaMA.jsonl')\n",
    "generated_data = load_jsonl('generated_test_results_few_shot_LLaMA.jsonl')\n",
    "\n",
    "# Function to extract clean question text\n",
    "def extract_combined_text(data_entry):\n",
    "    \"\"\"Extract and normalize the question and choices from a data entry.\"\"\"\n",
    "    output_text = data_entry.get('output', data_entry.get('generated_response', ''))\n",
    "    \n",
    "    if not output_text:\n",
    "        return \"\"\n",
    "\n",
    "    # Ensure case normalization and consistent spacing\n",
    "    output_text = output_text.strip().lower()\n",
    "\n",
    "    question_start = output_text.find(\"question:\")\n",
    "    choices_start = output_text.find(\"choices:\")\n",
    "\n",
    "    if question_start == -1 or choices_start == -1:\n",
    "        return output_text  # Return full text if markers are missing\n",
    "\n",
    "    question_text = output_text[question_start + len(\"question:\"):choices_start].strip()\n",
    "    choices_text = output_text[choices_start:].strip()\n",
    "\n",
    "    return f\"{question_text} {choices_text}\".replace(\"\\n\", \" \").strip()\n",
    "\n",
    "# Extract and preprocess text for training and generated data\n",
    "training_texts = [extract_combined_text(entry) for entry in training_data]\n",
    "generated_texts = [extract_combined_text(entry) for entry in generated_data]\n",
    "\n",
    "# Ensure we only compare valid entries\n",
    "training_texts = [text for text in training_texts if text]\n",
    "generated_texts = [text for text in generated_texts if text]\n",
    "\n",
    "# Vectorize all questions together\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_all = vectorizer.fit_transform(training_texts + generated_texts)\n",
    "\n",
    "# Separate training and generated TF-IDF matrices\n",
    "tfidf_train = tfidf_all[:len(training_texts)]\n",
    "tfidf_gen = tfidf_all[len(training_texts):]\n",
    "\n",
    "# Compute full pairwise similarity matrix\n",
    "similarity_matrix = cosine_similarity(tfidf_gen, tfidf_train)\n",
    "\n",
    "# Compare each generated question with all training questions\n",
    "results = []\n",
    "total_similarity = 0\n",
    "num_comparisons = 0\n",
    "max_similarity_overall = 0.0\n",
    "\n",
    "for gen_idx, gen_entry in enumerate(generated_data):\n",
    "    gen_combined = generated_texts[gen_idx]\n",
    "    \n",
    "    # Get similarities for this generated question\n",
    "    similarities = similarity_matrix[gen_idx]\n",
    "    \n",
    "    # Sort similarities in descending order\n",
    "    sorted_indices = similarities.argsort()[::-1]\n",
    "    \n",
    "    most_similar_train_questions = []\n",
    "    for idx in sorted_indices[:3]:  # Store top 3 most similar questions\n",
    "        most_similar_train_questions.append({\n",
    "            \"Training Question\": training_texts[idx],\n",
    "            \"Similarity Percentage\": round(similarities[idx] * 100, 2)\n",
    "        })\n",
    "    \n",
    "    # Update statistics\n",
    "    max_similarity = max(similarities) if len(similarities) > 0 else 0.0\n",
    "    max_similarity_overall = max(max_similarity_overall, max_similarity)\n",
    "    total_similarity += sum(similarities)\n",
    "    num_comparisons += len(similarities)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Generated Question\": gen_combined,\n",
    "        \"Most Similar Training Questions\": most_similar_train_questions\n",
    "    })\n",
    "\n",
    "# Calculate overall average similarity\n",
    "average_similarity = round((total_similarity / num_comparisons) * 100, 2) if num_comparisons > 0 else 0\n",
    "\n",
    "# Save the results to a JSONL file\n",
    "output_filename = \"Generated_Questions_Similarity_Analysis_few_shot_LLaMA_with_generated_fULL_LLaMA.jsonl\"\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "# Save overall statistics separately\n",
    "summary_filename = \"Generated_Questions_Similarity_Analysis_few_shot_LLaMA_with_generated_fULL_LLaMA_summary.jsonl\"\n",
    "summary_output = {\n",
    "    \"Overall Average Similarity Percentage\": average_similarity,\n",
    "    \"Highest Similarity Overall Percentage\": round(max_similarity_overall * 100, 2)\n",
    "}\n",
    "\n",
    "with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_output, f, indent=4)\n",
    "\n",
    "print(f\"✅ Similarity analysis complete. Results saved to {output_filename} and summary to {summary_filename}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
